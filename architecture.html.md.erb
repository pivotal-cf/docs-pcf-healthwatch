---
title: Healthwatch Architecture
owner: Healthwatch
---

<strong><%= modified_date %></strong>

This topic describes the architecture of the Healthwatch, Healthwatch Exporter for VMware Tanzu
Application Service for VMs (TAS for VMs), and Healthwatch Exporter for Tanzu Kubernetes Grid
Integrated Edition (TKGI) tiles. This topic also describes the possible configurations for
monitoring metrics across multiple foundations.


## <a id='architecture-overview'></a> Overview of Healthwatch Architecture

There are three tiles that form the Healthwatch architecture: Healthwatch, Healthwatch Exporter
for TAS for VMs, and Healthwatch Exporter for TKGI.

A complete Healthwatch installation includes the Healthwatch tile, as well as at least one
Healthwatch Exporter tile. However, you can deploy and use each tile separately as part of
an alternate monitoring configuration.

You must install a Healthwatch Exporter tile on each Ops Manager foundation you want to monitor.
You can install the Healthwatch tile on the same foundation or on a different foundation, depending
on your desired monitoring configuration.

You can also configure the Healthwatch Exporter tiles to expose metrics to a service or database
located outside your Ops Manager foundation, such as an external time-series database (TSDB)
or an installation of the Healthwatch tile on the TKGI Control Plane. This does not require
you to install the Healthwatch tile.

For a detailed explanation of the architecture for each tile, a list of open ports required
for each component, and the possible configurations for monitoring metrics across foundations,
see the following sections:

* [Healthwatch Tile Architecture](#architecture-hw)
* [Healthwatch Exporter for TAS for VMs Architecture](#architecture-tas)
* [Healthwatch Exporter for TKGI Architecture](#architecture-tkgi)
* [Configuration Options](#configuration-options)


## <a id='architecture-hw'></a> Healthwatch Tile Architecture

When you install the Healthwatch tile, Healthwatch deploys instances of Prometheus, Grafana,
and MySQL.

The Prometheus instance scrapes and stores metrics from the Healthwatch Exporter tiles and
enables you to configure alerts with Alertmanager. Healthwatch then exports the collected metrics
to dashboards in the Grafana UI, enabling you to visualize the data with charts and graphs
and create customized dashboards for long-term monitoring and troubleshooting. MySQL is used
only to store your Grafana settings and does not store any time series data.

An Nginx proxy is deployed in front of the Prometheus instance.

![A diagram that shows how the Prometheus, MySQL instance, and Nginx proxy relate to the Grafana instance](images/Healthwatch.png)

### <a id='ha-mode'></a> High Availability

You can deploy the Healthwatch tile in high availability (HA) mode with three MySQL nodes and
two MySQL Proxy nodes, or in non-HA mode with one MySQL node and one MySQL Proxy node.

### <a id='scaling'></a> Component Scaling

Healthwatch deploys a single Grafana VM by default. If you need Grafana to be HA, you can scale
your Grafana instance horizontally.

Healthwatch deploys two Prometheus VMs by default. You can scale your Prometheus instance vertically,
but you should not scale it horizontally.

### <a id='network-rules-hw'></a> Networking Rules for the Healthwatch Tile

The table below describes the ports you must open for each Healthwatch component:

<table>
  <tr>
    <th style="width: 22%">This component ...</th>
    <th style="width: 25%">Must communicate with ...</th>
    <th style="width: 20%">Default TCP Port</th>
    <th style="width: 37%">Notes</th>
  </tr>
  <tr>
    <td><code>grafana</code></td>
    <td>
      <ul>
        <li><code>tsdb</code></li>
        <li><code>pxc-proxy</code></li>
        <li>External alerting URLs</li>
        <li>External data sources</li>
        <li>External authentication</li>
        <li>External SMTP server</li>
      </ul>
    </td>
    <td>
      <ul>
        <li><code>4449</code></li>
        <li><code>3306</code></li>
      </ul>
    </td>
    <td>Additional networking rules may be required for any external connections listed. For
      example, <code>443</code> for UAA.</td>
  </tr>
  <tr>
    <td><code>blackbox-exporter</code></td>
    <td>External canary target URLs</td>
    <td>N/A</td>
    <td>Additional networking rules may be required, depending on your external canary target
      URL configuration.</td>
  </tr>
  <tr>
    <td><code>tsdb</code></td>
    <td>
      <ul>
        <li><code>blackbox-exporter</code></li>
        <li>All VMs deployed by Healthwatch Exporter tiles</li>
      </ul>
    </td>
    <td><code>9090</code></td>
    <td></td>
  </tr>
  <tr>
    <td><code>tsdb</code> (for TKGI cluster discovery)</td>
    <td>For each cluster:
      <ul>
        <li>Kube API Server</li>
        <li>Kube Controller Manager</li>
        <li>Kube Scheduler</li>
        <li>etcd (Telegraf output plugin)</li>
      </ul>
    </td>
    <td>
      <ul>
        <li><code>8443</code></li>
        <li><code>10252</code></li>
        <li><code>10251</code></li>
        <li><code>10200</code></li>
      </ul>
    </td>
    <td>You only need to open these ports if you configure TKGI cluster discovery.</td>
  </tr>
</table>


## <a id='architecture-tas'></a> Healthwatch Exporter for TAS for VMs Architecture

The **Healthwatch Exporter for TAS for VMs** tile deploys metric exporter VMs to generate each
type of metric related to the health of your TAS for VMs deployment.

Healthwatch Exporter for TAS for VMs sends metrics through the Loggregator Firehose to a Prometheus
exposition endpoint on the associated metric exporter VMs. The Prometheus instance that exists
within your metrics monitoring system then scrapes the exposition endpoints on the metric exporter
VMs and imports those metrics into your monitoring system.

You can scale the VMs that Healthwatch Exporter for TAS for VMs deploys vertically, but should
not scale them horizontally.

### <a id='network-rules-tas'></a> Networking Rules for Healthwatch Exporter for TAS for VMs

The table below describes the ports you must open for each Healthwatch Exporter for TAS for
VMs component:

<table>
  <tr>
    <th style="width: 22%">This component ...</th>
    <th style="width: 25%">Must communicate with ...</th>
    <th style="width: 20%">Default TCP Port</th>
  </tr>
  <tr>
    <td><code>bosh-deployments-exporter</code></td>
    <td>
      <ul>
        <li>BOSH Director UAA</li>
        <li>BOSH Director</li>
      </ul>
    </td>
    <td>
      <ul>
        <li><code>8443</code></li>
        <li><code>25555</code></li>
      </ul>
    </td>
  </tr>
  <tr>
    <td><code>bosh-health-exporter</code></td>
    <td>
      <ul>
        <li>BOSH Director UAA</li>
        <li>BOSH Director</li>
      </ul>
    </td>
    <td>
      <ul>
        <li><code>8443</code></li>
        <li><code>25555</code></li>
      </ul>
    </td>
  </tr>
  <tr>
    <td><code>cert-expiration-exporter</code></td>
    <td>Ops Manager</td>
    <td><code>443</code></td>
  </tr>
  <tr>
    <td><code>pas-exporter-counter</code></td>
    <td>Reverse Log Proxy (RLP) nozzle</td>
    <td><code>8082</code></td>
  </tr>
  <tr>
    <td><code>pas-exporter-gauge</code></td>
    <td>RLP nozzle</td>
    <td><code>8082</code></td>
  </tr>
  <tr>
    <td><code>pas-exporter-timer</code></td>
    <td>RLP nozzle</td>
    <td><code>8082</code></td>
  </tr>
  <tr>
    <td><code>pas-sli-exporter</code></td>
    <td>
      <ul>
        <li>CAPI</li>
        <li>UAA</li>
      </ul>
    </td>
    <td>
      <ul>
        <li><code>443</code></li>
        <li><code>443</code></li>
      </ul>
    </td>
  </tr>
</table>


## <a id='architecture-tkgi'></a> Healthwatch Exporter for TKGI Architecture

The **Healthwatch Exporter for TKGI** tile deploys metric exporter VMs to generate SLIs related
to the health of your TKGI deployment.

The Prometheus instance that exists within your metrics monitoring system then scrapes the
Prometheus exposition endpoints on the metric exporter VMs and imports those metrics into your
monitoring system.

You can scale the VMs that Healthwatch Exporter for TKGI deploys vertically, but should not
scale them horizontally.

### <a id='network-rules-tkgi'></a> Networking Rules for Healthwatch Exporter for TKGI

The table below describes the ports you must open for each Healthwatch Exporter for TKGI component:

<table>
  <tr>
    <th style="width: 22%">This component ...</th>
    <th style="width: 25%">Must communicate with ...</th>
    <th style="width: 20%">Default TCP Port</th>
  </tr>
  <tr>
    <td><code>bosh-deployments-exporter</code></td>
    <td>
      <ul>
        <li>BOSH Director UAA</li>
        <li>BOSH Director</li>
      </ul>
    </td>
    <td>
      <ul>
        <li><code>8443</code></li>
        <li><code>25555</code></li>
      </ul>
    </td>
  </tr>
  <tr>
    <td><code>bosh-health-exporter</code></td>
    <td>
      <ul>
        <li>BOSH Director UAA</li>
        <li>BOSH Director</li>
      </ul>
    </td>
    <td>
      <ul>
        <li><code>8443</code></li>
        <li><code>25555</code></li>
      </ul>
    </td>
  </tr>
  <tr>
    <td><code>cert-expiration-exporter</code></td>
    <td>Ops Manager</td>
    <td><code>443</code></td>
  </tr>
  <tr>
    <td><code>pks-exporter</code></td>
    <td>
      <ul>
        <li>BOSH Director UAA</li>
        <li>BOSH Director metrics agent</li>
      </ul>
    </td>
    <td>
      <ul>
        <li><code>8443</code></li>
        <li><code>25595</code></li>
      </ul>
    </td>
  </tr>
  <tr>
    <td><code>pks-sli-exporter</code></td>
    <td>
      <ul>
        <li>TKGI API UAA</li>
        <li>TKGI API</li>
      </ul>
    </td>
    <td>
      <ul>
        <li><code>8443</code></li>
        <li><code>9021</code></li>
      </ul>
    </td>
  </tr>
</table>


## <a id='configuration-options'></a> Configuration Options

Healthwatch is flexible, allowing you to monitor metrics across a variety of platform and foundation
configurations. The sections below describe the most common configuration scenarios:

* [Monitoring TAS for VMs on a Single Ops Manager Foundation](#tas-single-foundation)
* [Monitoring TKGI on a Single Ops Manager Foundation](#tkgi-single-foundation)
* [Monitoring TAS for VMs and TKGI on a Single Ops Manager Foundation](#tas-tkgi-single-foundation)
* [Monitoring TAS for VMs on a Different Ops Manager Foundation](#tas-different-foundation)
* [Monitoring TKGI on a Different Ops Manager Foundation](#tkgi-different-foundation)

### <a id='tas-single-foundation'></a> Monitoring TAS for VMs on a Single Ops Manager Foundation

If you only want to monitor a single Ops Manager foundation that has TAS for VMs installed,
install the Healthwatch tile and Healthwatch Exporter for TAS for VMs on the same foundation.
The Healthwatch tile automatically detects Healthwatch Exporter for TAS for VMs on the same
foundation and adds a scrape job for Healthwatch Exporter for TAS for VMs to the Prometheus
instance.

For more information about installing and configuring the Healthwatch tile and Healthwatch
Exporter for TAS for VMs, see the following topics:

* [Installing a Tile Manually](installing/installing-manually.html) or [Installing, Configuring,
and Deploying a Tile Through an Automated Pipeline](#automated-pipeline.html)

* [Configuring Healthwatch](configuring/configuring-healthwatch.html)

* [Configuring Healthwatch Exporter for TAS for VMs](configuring/configuring-exporter-tas.html).

### <a id='tkgi-single-foundation'></a> Monitoring TKGI on a Single Ops Manager Foundation

If you only want to monitor a single Ops Manager foundation that has TKGI installed, install
the Healthwatch tile and Healthwatch Exporter for TKGI on the same foundation. The Healthwatch
tile automatically detects Healthwatch Exporter for TKGI on the same foundation and adds a
scrape job for Healthwatch Exporter for TKGI to the Prometheus instance.

For more information about installing and configuring the Healthwatch tile and Healthwatch
Exporter for TKGI, see the following topics:

* [Installing a Tile Manually](installing/installing-manually.html) or [Installing, Configuring,
and Deploying a Tile Through an Automated Pipeline](#automated-pipeline.html)

* [Configuring Healthwatch](configuring/configuring-healthwatch.html)

* [Configuring Healthwatch Exporter for TKGI](configuring/configuring-exporter-tkgi.html).

### <a id='tas-tkgi-single-foundation'></a> Monitoring TAS for VMs and TKGI on a Single Ops Manager Foundation

If you only want to monitor a single Ops Manager foundation that has both TAS for VMs and TKGI
installed, install the Healthwatch tile, Healthwatch Exporter for TAS for VMs, and Healthwatch
Exporter for TKGI on the same foundation. The Healthwatch tile automatically detects Healthwatch
Exporter for TAS for VMs and Healthwatch Exporter for TKGI on the same foundation and adds
scrape jobs for both Healthwatch Exporter tiles to the Prometheus instance.

For more information about installing and configuring the Healthwatch tile, Healthwatch Exporter
for TAS for VMs, and Healthwatch Exporter for TKGI, see the following topics:

* [Installing a Tile Manually](installing/installing-manually.html) or [Installing, Configuring,
and Deploying a Tile Through an Automated Pipeline](#automated-pipeline.html)

* [Configuring Healthwatch](configuring/configuring-healthwatch.html)

* [Configuring Healthwatch Exporter for TAS for VMs](configuring/configuring-exporter-tas.html).

* [Configuring Healthwatch Exporter for TKGI](configuring/configuring-exporter-tkgi.html).

### <a id='tas-different-foundation'></a> Monitoring TAS for VMs on a Different Ops Manager Foundation

You can monitor several Ops Manager foundations that have TAS for VMs installed from a Healthwatch
tile that you install on a separate Ops Manager foundation or the TKGI Control Plane. To do
so, install the Healthwatch tile on either an Ops Manager foundation or the TKGI Control Plane.
Then, install Healthwatch Exporter for TAS for VMs and open the ports for the metric exporter
VMs that Healthwatch Exporter for TAS for VMs deploys on each Ops Manager foundation you want
to monitor. For more information about the ports you must open for each metric exporter VM,
see [Networking Rules for Healthwatch Exporter for TAS for VMs](#network-rules-tas) above.

Once you have installed Healthwatch Exporter for TAS for VMs and opened the required ports
on each Ops Manager foundation you want to monitor, add a scrape job for each Healthwatch Exporter
for TAS for VMs tile in the **Prometheus Configuration** pane of the Healthwatch tile that
you installed on your monitoring Ops Manager foundation or the TKGI Control Plane. To add a
scrape job for a Healthwatch Exporter TAS for VMs tile:

1. Retrieve the Ops Manager root certificate authority (CA) for the foundation you want to
monitor. For more information, see [Retrieve the Ops Manager Root CA](https://docs.pivotal.io/ops-manager/security/pcf-infrastructure/managing-certificates.html#root-certs)
in _Managing Certificates with the Ops Manager API_ in the Ops Manager documentation.

1. Nagivate to the Ops Manager Installation Dashboard for the foundation you want to monitor.

1. Click the **Healthwatch Exporter for Tanzu Application Service** tile.

1. Select the **Credentials** tab.

1. In the row for **Healthwatch Exporter Client Mtls**, click **Link to Credential**.

1. Record the credentials for **Healthwatch Exporter Client Mtls**.

1. Navigate to the Healthwatch tile installed on your monitoring Ops Manager foundation or
the TKGI Control Plane.

1. Select **Prometheus Configuration**.

1. Under **Additional Scrape Config Jobs**, click **Add**.

1. For **TSDB Scrape job**, provide the configuration YAML for the scrape job for Healthwatch
Exporter for TAS for VMs, similar to the following example:

    ```
    - job_name: FOUNDATION-NAME
      metrics_path: /metrics
      scheme: https
      static_configs:
        - targets:
          - "<gauge exporter ip>:9090"
          - "<counter exporter ip>:9090"
          - "<timer exporter ip>:9090"
    ```
    Where `FOUNDATION-NAME` is the name of the foundation you want to monitor.

1. For **TLS Config Certificate Authority**, enter the Ops Manager root CA that you retrieved
in a previous step.

1. For **TLS Config Certificate and Private Key**, enter the certificate and private key from
**Healthwatch Exporter Client Mtls** that you recorded from the **Credentials** tab in the
Healthwatch Exporter for TAS for VMs tile in a previous step.

1. For **TLS Config Server Name**, enter the name of the server that facilitates TLS communication
between the Prometheus instance in the Healthwatch tile and the metric exporter VMs that Healthwatch
Exporter for TAS for VMs deploys.

### <a id='tkgi-different-foundation'></a> Monitoring TKGI on a Different Ops Manager Foundation

You can monitor several Ops Manager foundations that have TKGI installed from a Healthwatch
tile that you install on a separate Ops Manager foundation or the TKGI Control Plane. To do
so, install the Healthwatch tile on either an Ops Manager foundation or the TKGI Control Plane.
Then, install Healthwatch Exporter for TKGI and open the ports for the metric exporter VMs
that Healthwatch Exporter for TKGI deploys on each Ops Manager foundation you want to monitor.
For more information about the ports you must open for each metric exporter VM, see [Networking
Rules for Healthwatch Exporter for TKGI](#network-rules-tkgi) above.

Once you have installed Healthwatch Exporter for TKGI and opened the required ports on each
Ops Manager foundation you want to monitor, add a scrape job for each Healthwatch Exporter
for TKGI tile in the **Prometheus Configuration** pane of the Healthwatch tile that you installed
on your monitoring Ops Manager foundation or the TKGI Control Plane. To add a scrape job for
a Healthwatch Exporter TKGI tile:

1. Retrieve the Ops Manager root CA for the foundation you want to monitor. For more information,
see [Retrieve the Ops Manager Root CA](https://docs.pivotal.io/ops-manager/security/pcf-infrastructure/managing-certificates.html#root-certs)
in _Managing Certificates with the Ops Manager API_ in the Ops Manager documentation.

1. Nagivate to the Ops Manager Installation Dashboard for the foundation you want to monitor.

1. Click the **Healthwatch Exporter for Tanzu Kubernetes Grid - Integrated** tile.

1. Select the **Credentials** tab.

1. In the row for **Healthwatch Exporter Client Mtls**, click **Link to Credential**.

1. Record the credentials for **Healthwatch Exporter Client Mtls**.

1. Navigate to the Healthwatch tile installed on your monitoring Ops Manager foundation or
the TKGI Control Plane.

1. Select **Prometheus Configuration**.

1. Under **Additional Scrape Config Jobs**, click **Add**.

1. For **TSDB Scrape job**, provide the configuration YAML for the scrape job for Healthwatch
Exporter for TKGI, similar to the following example:

    ```
    - job_name: FOUNDATION-NAME
      metrics_path: /metrics
      scheme: https
      static_configs:
        - targets:
          - "<gauge exporter ip>:9090"
          - "<counter exporter ip>:9090"
          - "<timer exporter ip>:9090"
    ```
    Where `FOUNDATION-NAME` is the name of the foundation you want to monitor.

1. For **TLS Config Certificate Authority**, enter the Ops Manager root CA that you retrieved
in a previous step.

1. For **TLS Config Certificate and Private Key**, enter the certificate and private key from
**Healthwatch Exporter Client Mtls** that you recorded from the **Credentials** tab in the
Healthwatch Exporter for TKGI tile in a previous step.

1. For **TLS Config Server Name**, enter the name of the server that facilitates TLS communication
between the Prometheus instance in the Healthwatch tile and the metric exporter VMs that Healthwatch
Exporter for TKGI deploys.
