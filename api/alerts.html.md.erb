---
title: Configuring PCF Healthwatch Alerts
owner: PCF Healthwatch
---

This topic describes how to use the Pivotal Cloud Foundry (PCF) Healthwatch API to retrieve and configure alert configurations. It also provides information about configuring PCF Event Alerts to receive push notifications when a PCF Healthwatch alert occurs. 

<p class="note"><strong>Note</strong>: PCF Healthwatch stores all data points for 25 hours and then prunes them. Any active alerts that are pruned reissue an alert every 24 hours if the related metrics are not yet recovered to a normal state.</p>

Currently, two main types of alert configurations are supported: Out-of-the-Box and Deployment-specific. Through this API, consumers can do the following:

- View current alert configurations
- Update Out-of-the-Box threshold values
- Create or delete deployment-specific configurations based on existing Out-of-the-Box configurations

##<a id='prerequisites'></a>Prerequisites/Assumptions

The steps in this document assume that you can [generate bearer tokens for a UAA client](https://docs.pivotal.io/pivotalcf/uaa/uaa-user-management.html) with the `healthwatch.read` (`GET` only) and `healthwatch.admin` (both `GET` and `POST`) scopes.

After creating a user that has `healthwatch.read` or `healthwatch.admin` scopes, follow these steps to authenticate against UAA:

```
uaac token client get <my_healthwatch_admin_client> -s <my_healthwatch_admin_secret>
```

At this point you are properly authenticated and ready to start using the Healthwatch Alerts API.

##<a id='info'></a>Healthwatch API Status

Test the availability of the Healthwatch API by hitting the `/info` endpoint with a `GET` request:

```
curl https://healthwatch-api.SYSTEM-DOMAIN/info
```

The expected response is a `200`/`OK` with the message `"HAPI is happy"`.

##<a id='get'></a>View All Alert Configurations
### `GET /v1/alert-configurations`

To view a list of alert configurations, send a `GET` request to the `/alert-configurations` endpoint:

```
uaac curl https://healthwatch-api.SYSTEM-DOMAIN/v1/alert-configurations
```

This returns a JSON array of alert configurations:

```
[
    {
        "query": "origin == 'some_origin' and name == 'Some.Metric.Name'",
        "threshold": {
            "critical": 95,
            "warning": 85,
            "type": "UPPER"
        }
    },
    {
        "query": "origin == 'some_origin' and name == 'Another.Metric.Name'",
        "threshold": {
            "critical": 9,
            "warning": 28,
            "type": "LOWER"
        }
    },
    {
        "query": "origin == 'another_origin' and name == 'Some.Metric.Name'",
        "threshold": {
            "critical": 1,
            "type": "EQUALITY"
        }
    }
]
```

The `query` and `threshold` properties are covered in detail below.

##<a id='get_with_query'></a>View Specific Alert Configurations
### `GET /v1/alert-configurations?q=...`

To narrow the results of a `GET` request, add a `query` to the URL in a parameter named `q`:

```
uaac curl "https://healthwatch-api.SYSTEM-DOMAIN/v1/alert-configurations?q=origin == 'some_origin' and name == 'Some.Metric.Name'" 
```

This returns a JSON array of alert configurations, filtered against the provided `query`:

```
[
    {
        "query": "origin == 'some_origin' and name == 'Some.Metric.Name'",
        "threshold": {
            "critical": 95,
            "warning": 85,
            "type": "UPPER"
        }
    }
]
```

##<a id='post'></a>Update Alert Configurations
### `POST /v1/alert-configurations`

To update an existing alert configuration, make a `POST` request to the `alert-configurations` endpoint with the updated data:

```
uaac curl -X POST "https://healthwatch-api.SYSTEM-DOMAIN/v1/alert-configurations"  \
      -H "Content-Type: application/json" \
      --data "{\"query\":\"origin == 'some_origin' and name == 'Some.Metric.Name'\",\"threshold\":{\"critical\":90,\"warning\":80,\"type\":\"UPPER\"}}"

```

See the following example output:

```
{
    "query": "origin == 'some_origin' and name == 'Some.Metric.Name'",
    "threshold": {
        "critical": 95,
        "warning": 85,
        "type": "UPPER"
    }
}
```

<p class="note warning"><strong>Warning</strong>: These alert configurations cannot be deleted. In order to revert your changes, update the alert back to its <a href="#defaults">default values</a>.</p>  

##<a id='post2'></a>Create Alert Configurations for Isolation Segments
### `POST /v1/alert-configurations`

Specific thresholds can be set for an Isolation Segments by extending existing alert configurations with a deployment specifier. For example, to create an isolation segment alert configuration for the above alert, run the following:

```
uaac curl -X POST "https://healthwatch-api.SYSTEM-DOMAIN/v1/alert-configurations"  \
      -H "Content-Type: application/json" \
      --data "{\"query\":\"origin == 'some_origin' and name == 'Some.Metric.Name' and deployment == 'Some-Isolated-Deployment'\",\"threshold\":{\"critical\":55,\"warning\":45,\"type\":\"UPPER\"}}"
```

The created alert configuration is echoed back in the following response:

```
{
    "query": "origin == 'some_origin' and name == 'Some.Metric.Name' and deployment == 'Some-Isolated-Deployment'",
    "threshold": {
        "critical": 55,
        "warning": 45,
        "type": "UPPER"
    }
}
```
<p class="note"><strong>Note</strong>: You can delete Isolation Segment alert configurations only if you created them with the above method.</p>

##<a id='delete'></a>Delete Isolation Segment Alert Configurations

To delete a user-created alert configuration for an isolation segment, add a `query` to the URL in a parameter named `q`. 

`DELETE /v1/alert-configurations?q=...`

See the following example:

```
uaac curl -X DELETE "https://healthwatch-api.SYSTEM-DOMAIN/v1/alert-configurations?q=origin == 'some_origin' and name == 'Some.Metric.Name' and deployment == 'Some-Isolated-Deployment'"
```

This returns the number of deleted alert configurations. See the following example output.

```
1
```

<p class="note"><strong>Note</strong>: You can delete Isolation Segment alert configurations only if you created them through the Healthwatch API.</p>

## <a id='disable'></a> Disable Alerts on a Metric

PCF Healthwatch does not support disabling alerts on a specific metric. To ensure that PCF Healthwatch does not alert on a metric, update the threshold of the alert to a value that will never trigger an alert.

For more information about thresholds, see [Thresholds](#thresholds).

For more information about updating alert configurations, see [Update Alert Configurations](#post).

##<a id='queries'></a>Queries

The `query` field is used in two ways:

* `GET` requests: The `query` filters the alert configurations being queried.
* `POST` requests: The `query` specifies the alert configuration being updated.
* `DELETE` requests: The `query` filters the alert configurations being deleted.

The `query` associated with an alert configuration denotes the trigger conditions for the alert.

A well-formed `query` is a valid [Spring Expression Language (SpEL)](https://docs.spring.io/spring/docs/4.3.14.RELEASE/spring-framework-reference/html/expressions.html) expression that uses only the equality, `"=="`, and conjunction, `"and"`, operators. For example:

```
"origin == 'some_origin' and name == 'Some.Metric.Name'"  # valid
"origin  > 'some_origin' and name == 'Some.Metric.Name'"  # invalid (uses '>')
"origin == 'some_origin'  or name == 'Some.Metric.Name'"  # invalid (uses 'or')
```

The following fields can be queried:

- `origin`&nbsp;&nbsp;&nbsp;*(required)*
- `name`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*(required)*
- `job`
- `deployment`

##<a id='thresholds'></a>Thresholds

The `threshold` field contains a threshold `type`, as well as `critical` and `warning` threshold values. The `type` can be `"UPPER"`, `"LOWER"`, `"EQUALITY"`, or `"INEQUALITY"`.

Alert configurations whose thresholds are of the `UPPER` type trigger their alerts when the actual metric value is *above* the `warning` value, and again when above the `critical` value.

Thresholds with the `LOWER` type work the same way, except the alerts trigger when the metric falls *below* the thresholds.

The `EQUALITY` alerts trigger when the metric value is **not** exactly equal to the `critical` threshold. These alerts do not have `warning` thresholds.

The `INEQUALITY` alerts trigger when the metric value **is** exactly equal to the `critical` threshold. These alerts do not have `warning` thresholds.

##<a id='defaults'></a>Supported Alerts

This section describes the default Warning and Critical alerts for PCF Healthwatch. Each alert includes recommended thresholds for metrics monitored by Healthwatch. 

Pivotal recommends customizing the default thresholds for alerts indicated with a <sup>1</sup> in the following tables based on your environment. You can determine the best threshold for your environment by monitoring the metrics over time and noting the metric values that indicate acceptable and unacceptable system performance and health. For more information about updating alert configurations in PCF Healthwatch, see [Update Alert Configurations](#post).

By default, PCF Healthwatch includes the configurable alerts in the tables below.
You can learn more about the metrics PCF Healthwatch emits here: [PCF Healthwatch Metrics](../metrics.html).


###<a id='performance-alerts'></a>Performance Alerts

<table>
    <tr>
        <th style="width: 20%">Alert</th>
        <th>Metric</th>
        <th>Threshold</th>
    </tr>
    <tr>
        <td>Active Locks Held</td>
        <td>
            <strong>Name</strong>: ActiveLocks
            <br><strong>Origin</strong>: locket
            <br><strong>Category</strong>: Compute Performance
        </td>
        <td>
            <strong>Threshold Type</strong>: EQUALITY
            <br><strong>Critical</strong>: 4
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Active Presences Held<sup>1</sup></td>
        <td>
            <strong>Name</strong>: ActivePresences
            <br><strong>Origin</strong>: locket
            <br><strong>Category</strong>: Compute Performance
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 200
            <br><strong>Warning</strong>: 150
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 15
        </td>
    </tr>
    <tr>
        <td>Auctioneer Time to Fetch Cell State</td>
        <td>
            <strong>Name</strong>: AuctioneerFetchStatesDuration
            <br><strong>Origin</strong>: auctioneer
            <br><strong>Category</strong>: Compute Performance
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 5000000000
            <br><strong>Warning</strong>: 2000000000
            <br><strong>Unit</strong>: ns
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>App Instances Placement Failures Rate </td>
        <td>
            <strong>Name</strong>: AuctioneerLRPAuctionsFailed
            <br><strong>Origin</strong>: auctioneer
            <br><strong>Category</strong>: App Instances
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 1
            <br><strong>Warning</strong>: .5
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>App Instance Starts Rate<sup>1</sup> </td>
        <td>
            <strong>Name</strong>: AuctioneerLRPAuctionsStarted
            <br><strong>Origin</strong>: auctioneer
            <br><strong>Category</strong>: App Instances
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 100
            <br><strong>Warning</strong>: 50
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td> Router Exhausted Connections<sup>1</sup> </td>
        <td>
            <strong>Name</strong>: backend_exhausted_conns
            <br><strong>Origin</strong>: gorouter
            <br><strong>Category</strong>: Routing
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 10
            <br><strong>Warning</strong>: 5
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Number of Router 502 Bad Gateways<sup>1</sup></td>
        <td>
            <strong>Name</strong>: bad_gateways
            <br><strong>Origin</strong>: gorouter
            <br><strong>Category</strong>: Routing
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 40
            <br><strong>Warning</strong>: 30
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td> Task Placement Failures Rate</td>
        <td>
            <strong>Name</strong>: AuctioneerTaskAuctionsFailed
            <br><strong>Origin</strong>: auctioneer
            <br><strong>Category</strong>: App Instances
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 1
            <br><strong>Warning</strong>: .5
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td> BBS Time to Run LRP Convergence </td>
        <td>
            <strong>Name</strong>: ConvergenceLRPDuration
            <br><strong>Origin</strong>: bbs
            <br><strong>Category</strong>: Compute Performance
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 20000000000
            <br><strong>Warning</strong>: 10000000000
            <br><strong>Unit</strong>: ns
            <br><strong>Assessment Window (minutes)</strong>: 15
        </td>
    </tr>
    <tr>
        <td>Number of Crashed App Instances<sup>1</sup></td>
        <td>
            <strong>Name</strong>: CrashedActualLRPs
            <br><strong>Origin</strong>: bbs
            <br><strong>Category</strong>: App Instances
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 20
            <br><strong>Warning</strong>: 10
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Cloud Controller and Diego in Sync</td>
        <td>
            <strong>Name</strong>: Diego.<br/>AppsDomainSynced
            <br><strong>Origin</strong>: bbs
            <br><strong>Category</strong>: Compute Performance
        </td>
        <td>
            <strong>Threshold Type</strong>: EQUALITY
            <br><strong>Critical</strong>: 1
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Rate of Change in Running App Instances<sup>1</sup></td>
        <td>
            <strong>Name</strong>: Diego.<br/>LRPsAdded.1H
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: App Instances
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 100
            <br><strong>Warning</strong>: 50
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Router File Descriptors </td>
        <td>
            <strong>Name</strong>: file_descriptors
            <br><strong>Origin</strong>: gorouter
            <br><strong>Category</strong>: Routing
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 60000
            <br><strong>Warning</strong>: 50000
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>PAS MySQL Galera Cluster Status</td>
        <td>
            <strong>Name</strong>: Galera.<br/>ClusterStatusSum
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: MySQL
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.9999
            <br><strong>Warning</strong>: 2.9999
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>PAS MySQL Galera Cluster Size</td>
        <td>
            <strong>Name</strong>: Galera.<br/>TotalPercentageHealthyNodes
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: MySQL
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.3332
            <br><strong>Warning</strong>: 0.9999
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Healthwatch BOSH Director Test Availability</td>
        <td>
            <strong>Name</strong>: health.check.<br/>bosh.director.probe.available
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: BOSH Director
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.4
            <br><strong>Warning</strong>: 0.6
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 10
        </td>
    </tr>
    <tr>
        <td>Ops Manager Test Availability</td>
        <td>
            <strong>Name</strong>: health.check.<br/>OpsMan.probe.available
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Ops Manager
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.4
            <br><strong>Warning</strong>: 0.6
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Canary App Health Test Availability</td>
        <td>
            <strong>Name</strong>: health.check.<br/>CanaryApp.probe.available
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Canary App
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.4
            <br><strong>Warning</strong>: 0.6
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>CLI Health Test Availability </td>
        <td>
            <strong>Name</strong>: health.check.<br/>cliCommand.probe.available
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: CLI
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.4
            <br><strong>Warning</strong>: 0.6
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Healthwatch UI Availability </td>
        <td>
            <strong>Name</strong>: health.check.<br/>ui.available
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Healthwatch
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.4
            <br><strong>Warning</strong>: 0.6
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Healthwatch UI Availability </td>
        <td>
            <strong>Name</strong>: health.check.<br/>ui.available
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Healthwatch
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.4
            <br><strong>Warning</strong>: 0.6
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Healthwatch Nozzle Disconnects </td>
        <td>
            <strong>Name</strong>: ingestor.disconnects
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Healthwatch
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 10
            <br><strong>Warning</strong>: 5
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Healthwatch Ingestor Data Drops  </td>
        <td>
            <strong>Name</strong>: ingestor.dropped
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Healthwatch
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 20
            <br><strong>Warning</strong>: 10
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Healthwatch Ingestor Metrics Ingested  </td>
        <td>
            <strong>Name</strong>: ingestor.ingested
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Healthwatch
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.01
            <br><strong>Warning</strong>: 0.01
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 30
        </td>
    </tr>
    <tr>
        <td>Healthwatch Ingestor BOSH System Metrics Ingested</td>
        <td>
            <strong>Name</strong>: ingestor.ingested.<br/>boshSystemMetrics
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Healthwatch
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.01
            <br><strong>Warning</strong>: 0.01
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 30
        </td>
    </tr>
    <tr>
        <td>Router Handling Latency<sup>1</sup>  </td>
        <td>
            <strong>Name</strong>: latency
            <br><strong>Origin</strong>: gorouter
            <br><strong>Category</strong>: Routing
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 150
            <br><strong>Warning</strong>: 100
            <br><strong>Unit</strong>: ms
            <br><strong>Assessment Window (minutes)</strong>: 30
        </td>
    </tr>
    <tr>
        <td> UAA Request Latency</td>
        <td>
            <strong>Name</strong>: latency.uaa
            <br><strong>Origin</strong>: gorouter
            <br><strong>Category</strong>: Routing
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 150
            <br><strong>Warning</strong>: 100
            <br><strong>Unit</strong>: ms
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td> Locks Held by BBS</td>
        <td>
            <strong>Name</strong>: LockHeld
            <br><strong>Origin</strong>: bbs
            <br><strong>Category</strong>: Healthwatch
        </td>
        <td>
            <strong>Threshold Type</strong>: EQUALITY
            <br><strong>Critical</strong>: 1
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td> Locks Held by Auctioneer </td>
        <td>
            <strong>Name</strong>: LockHeld
            <br><strong>Origin</strong>: auctioneer
            <br><strong>Category</strong>: Compute Performance
        </td>
        <td>
            <strong>Threshold Type</strong>: EQUALITY
            <br><strong>Critical</strong>: 1
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>More App Instances Than Expected</td>
        <td>
            <strong>Name</strong>: LRPsExtra
            <br><strong>Origin</strong>: bbs
            <br><strong>Category</strong>: App Instances
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 10
            <br><strong>Warning</strong>: 5
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Fewer App Instances Than Expected </td>
        <td>
            <strong>Name</strong>: LRPsMissing
            <br><strong>Origin</strong>: bbs
            <br><strong>Category</strong>: App Instances
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 10
            <br><strong>Warning</strong>: 5
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Healthwatch Super Metrics Published</td>
        <td>
            <strong>Name</strong>: metrics.published
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Healthwatch
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0
            <br><strong>Warning</strong>: 20
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Time Since Last Route Register Received</td>
        <td>
            <strong>Name</strong>: ms_since_last_registry_update
            <br><strong>Origin</strong>: gorouter
            <br><strong>Category</strong>: Routing
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 30000
            <br><strong>Warning</strong>: 30000
            <br><strong>Unit</strong>: ms
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>PAS MySQL Server Availability</td>
        <td>
            <strong>Name</strong>: /mysql/available
            <br><strong>Origin</strong>: mysql
            <br><strong>Job</strong>: mysql, database
            <br><strong>Category</strong>: MySQL
        </td>
        <td>
            <strong>Threshold Type</strong>: EQUALITY
            <br><strong>Critical</strong>: 1
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>PAS MySQL Galera Cluster Node Readiness </td>
        <td>
            <strong>Name</strong>: /mysql/galera/wsrep_ready
            <br><strong>Origin</strong>: mysql
            <br><strong>Job</strong>: mysql, database
            <br><strong>Category</strong>: MySQL
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 1
            <br><strong>Warning</strong>: 0.9999
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Cell Rep Time to Sync</td>
        <td>
            <strong>Name</strong>: RepBulkSyncDuration
            <br><strong>Origin</strong>: rep
            <br><strong>Category</strong>: Compute Performance
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 10000000000
            <br><strong>Warning</strong>: 5000000000
            <br><strong>Unit</strong>: ns
            <br><strong>Assessment Window (minutes)</strong>: 15
        </td>
    </tr>
    <tr>
        <td>Number of Router 5XX Server Errors<sup>1</sup></td>
        <td>
            <strong>Name</strong>: responses.5xx
            <br><strong>Origin</strong>: gorouter
            <br><strong>Category</strong>: Routing
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 40
            <br><strong>Warning</strong>: 30
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Route Emitter Time to Sync<sup>1</sup> </td>
        <td>
            <strong>Name</strong>: RouteEmitterSyncDuration
            <br><strong>Origin</strong>: route_emitter
            <br><strong>Category</strong>: Compute Performance
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 10000000000
            <br><strong>Warning</strong>: 5000000000
            <br><strong>Unit</strong>: ns
            <br><strong>Assessment Window (minutes)</strong>: 15
        </td>
    </tr>
    <tr>
        <td>Number of Route Registration Messages Sent and Received</td>
        <td>
            <strong>Name</strong>: RouteRegistration.MessagesDelta
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Routing
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 50
            <br><strong>Warning</strong>: 30
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>BBS Time to Handle Requests</td>
        <td>
            <strong>Name</strong>: RequestLatency
            <br><strong>Origin</strong>: bbs
            <br><strong>Category</strong>: Compute Performance
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 10000000000
            <br><strong>Warning</strong>: 5000000000
            <br><strong>Unit</strong>: ns
            <br><strong>Assessment Window (minutes)</strong>: 15
        </td>
    </tr>
    <tr>
        <td>UAA Requests In Flight </td>
        <td>
            <strong>Name</strong>: server.inflight.count
            <br><strong>Origin</strong>: uaa
            <br><strong>Category</strong>: UAA
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 200
            <br><strong>Warning</strong>: 150
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>VM CPU </td>
        <td>
            <strong>Name</strong>: system.cpu.user
            <br><strong>Origin</strong>: bosh-system-metrics-forwarder
            <br><strong>Category</strong>: All Jobs
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 95
            <br><strong>Warning</strong>: 85
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>VM Ephemeral Disk Used</td>
        <td>
            <strong>Name</strong>: system.disk.<bbr/>ephemeral.percent
            <br><strong>Origin</strong>: bosh-system-metrics-forwarder
            <br><strong>Category</strong>: All Jobs
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 90
            <br><strong>Warning</strong>: 80
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>VM Persistent Disk Used </td>
        <td>
            <strong>Name</strong>: system.disk.<br/>persistent.percent
            <br><strong>Origin</strong>: bosh-system-metrics-forwarder
            <br><strong>Category</strong>: All Jobs
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 90
            <br><strong>Warning</strong>: 80
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>VM Disk Used </td>
        <td>
            <strong>Name</strong>: system.disk.<br/>system.percent
            <br><strong>Origin</strong>: bosh-system-metrics-forwarder
            <br><strong>Category</strong>: All Jobs
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 90
            <br><strong>Warning</strong>: 80
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>VM Health Check Recovery</td>
        <td>
            <strong>Name</strong>: system.healthy
            <br><strong>Origin</strong>: bosh-system-metrics-forwarder
            <br><strong>Category</strong>: All Jobs
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.4
            <br><strong>Warning</strong>: 0.6
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Router Throughput<sup>1</sup>  </td>
        <td>
            <strong>Name</strong>: total_requests
            <br><strong>Origin</strong>: gorouter
            <br><strong>Category</strong>: Routing
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 125000
            <br><strong>Warning</strong>: 100000
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Number of Router Routes Registered<sup>1</sup></td>
        <td>
            <strong>Name</strong>: total_routes
            <br><strong>Origin</strong>: gorouter
            <br><strong>Category</strong>: Routing
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 200
            <br><strong>Warning</strong>: 100
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>VM Memory Used</td>
        <td>
            <strong>Name</strong>: system.mem.percent
            <br><strong>Origin</strong>: bosh-system-metrics-forwarder
            <br><strong>Category</strong>: All Jobs
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 95
            <br><strong>Warning</strong>: 85
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>UAA Throughput Rate</td>
        <td>
            <strong>Name</strong>: uaa.throughput.rate
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Healthwatch
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 15000
            <br><strong>Warning</strong>: 12000
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Unhealthy Cells<sup>2</sup></td>
        <td>
            <strong>Name</strong>: UnhealthyCell
            <br><strong>Origin</strong>: rep
            <br><strong>Category</strong>: Compute Performance
        </td>
        <td>
            <strong>Threshold Type</strong>: EQUALITY
            <br><strong>Critical</strong>: 0
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
</table>

<sup>1</sup> Pivotal recommends customizing the default thresholds for these alerts based on your environment. You can determine the best threshold for your environment by monitoring the metrics over time and noting the metric values that indicate acceptable and unacceptable system performance and health. For more information about updating alert configurations in PCF Healthwatch, see [Update Alert Configurations](#post).<br/>
<sup>2</sup> We are alerting by cell for this metric. We will notify at a critical level when any Diego Cell has been unhealthy for 5 minutes.<br/>

###<a id='scaling-alerts'></a>Scaling Alerts

<table>
    <tr>
        <th style="width: 20%">Alert</th>
        <th>Metric</th>
        <th>Threshold</th>
    </tr>
    <tr>
        <td>Number of Available Free Chunks of Cell Memory</td>
        <td>
            <strong>Name</strong>: Diego.<br/>AvailableFreeChunks
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Capacity
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 1
            <br><strong>Warning</strong>: 2
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Number of Available Free Chunks of Cell Disk</td>
        <td>
            <strong>Name</strong>: Diego.<br/>AvailableFreeChunksDisk
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Capacity
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 50
            <br><strong>Warning</strong>: 100
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Remaining Cell Disk Available</td>
        <td>
            <strong>Name</strong>: Diego.<br/>TotalAvailableDiskCapacity.<br/>5M
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Capacity
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 6144
            <br><strong>Warning</strong>: 12288
            <br><strong>Unit</strong>: MBs
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Remaining Cell Memory Available<sup>1</sup></td>
        <td>
            <strong>Name</strong>: Diego.<br/>TotalAvailableMemoryCapacity.<br/>5M
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Capacity
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 32768
            <br><strong>Warning</strong>: 65536
            <br><strong>Unit</strong>: MBs
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Cell Container Capacity Available </td>
        <td>
            <strong>Name</strong>: Diego.<br/>TotalPercentageAvailableContainerCapacity.<br/>5M
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Capacity
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.35
            <br><strong>Warning</strong>: 0.35
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 30
        </td>
    </tr>
    <tr>
        <td>Cell Disk Available</td>
        <td>
            <strong>Name</strong>: Diego.<br/>TotalPercentageAvailableDiskCapacity.<br/>5M
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Capacity
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.35
            <br><strong>Warning</strong>: 0.35
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 30
        </td>
    </tr>
    <tr>
        <td>Cell Memory Available<sup>1</sup></td>
        <td>
            <strong>Name</strong>: Diego.<br/>TotalPercentageAvailableMemoryCapacity.<br/>5M
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Capacity
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.35
            <br><strong>Warning</strong>: 0.35
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 30
        </td>
    </tr>
    <tr>
        <td>Doppler Message Rate Capacity </td>
        <td>
            <strong>Name</strong>: Doppler.<br/>MessagesAverage.1M
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Logging
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 1000000
            <br><strong>Warning</strong>: 800000
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 60
        </td>
    </tr>
    <tr>
        <td>Log Transport Loss Rate </td>
        <td>
            <strong>Name</strong>: Firehose.<br/>LossRate.1M
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Logging
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 0.01
            <br><strong>Warning</strong>: 0.005
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Redis Counter Event Queue Size</td>
        <td>
            <strong>Name</strong>: redis.<br/>counterEventQueue.size
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Healthwatch
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 10000
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Redis Value Metric Queue Size </td>
        <td>
            <strong>Name</strong>: redis.<br/>valueMetricQueue.size
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Healthwatch
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 10000
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Syslog Adapter Capacity </td>
        <td>
            <strong>Name</strong>: SyslogDrain.<br/>Adapter.BindingsAverage.5M
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Logging
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 500
            <br><strong>Warning</strong>: 450
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 60
        </td>
    </tr>
    <tr>
        <td>Syslog Adapter Loss Rate</td>
        <td>
            <strong>Name</strong>: SyslogDrain.<br/>Adapter.LossRate.1M
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Logging
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 0.1
            <br><strong>Warning</strong>: 0.01
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Reverse Log Proxy Loss Rate</td>
        <td>
            <strong>Name</strong>: SyslogDrain.<br/>RLP.LossRate.1M
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Logging
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 0.1
            <br><strong>Warning</strong>: 0.01
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Router Instance CPU</td>
        <td>
            <strong>Name</strong>: system.cpu.user
            <br><strong>Origin</strong>: bosh-system-metrics-forwarder
            <br><strong>Job</strong>: router
            <br><strong>Category</strong>: Routing
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 70
            <br><strong>Warning</strong>: 60
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>UAA Instance CPU</td>
        <td>
            <strong>Name</strong>: system.cpu.user
            <br><strong>Origin</strong>: bosh-system-metrics-forwarder
            <br><strong>Job</strong>: uaa,<br/>control<sup>3</sup>
            <br><strong>Category</strong>: UAA
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 90
            <br><strong>Warning</strong>: 80
            <br><strong>Unit</strong>: Percent
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
</table>

<sup>1</sup> Pivotal recommends customizing the default thresholds for these alerts based on your environment. You can determine the best threshold for your environment by monitoring the metrics over time and noting the metric values that indicate acceptable and unacceptable system performance and health. For more information about updating alert configurations in PCF Healthwatch, see [Update Alert Configurations](#post).<br/>
<sup>3</sup> This handles two jobs to accommodate different job names between PAS and SRT*


###<a id='service-level-indicators'></a> Service Level Indicators

<table>
    <tr>
        <th style="width: 20%">Alert</th>
        <th>Metric</th>
        <th>Threshold</th>
    </tr>
    <tr>
        <td>BOSH Director Health </td>
        <td>
            <strong>Name</strong>: health.check.<br/>bosh.director.success
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: BOSH Director
        </td>
        <td>
            <strong>Threshold Type</strong>: EQUALITY
            <br><strong>Critical</strong>: 1
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 10
        </td>
    </tr>
    <tr>
        <td>Ops Manager Availability</td>
        <td>
            <strong>Name</strong>: health.check.<br/>OpsMan.available
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Ops Manager
        </td>
        <td>
            <strong>Threshold Type</strong>: EQUALITY
            <br><strong>Critical</strong>: 1
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 10
        </td>
    </tr>
    <tr>
        <td>Canary App Availability</td>
        <td>
            <strong>Name</strong>: health.check.<br/>CanaryApp.available
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Canary App
        </td>
        <td>
            <strong>Threshold Type</strong>: LOWER
            <br><strong>Critical</strong>: 0.5
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>Canary App Response Time </td>
        <td>
            <strong>Name</strong>: health.check.<br/>CanaryApp.responseTime
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: Canary App
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 30000
            <br><strong>Warning</strong>: 15000
            <br><strong>Unit</strong>: ms
            <br><strong>Assessment Window (minutes)</strong>: 5
        </td>
    </tr>
    <tr>
        <td>CF Push Time</td>
        <td>
            <strong>Name</strong>: health.check.<br/>cliCommand.pushTime
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: CLI
        </td>
        <td>
            <strong>Threshold Type</strong>: UPPER
            <br><strong>Critical</strong>: 120000
            <br><strong>Warning</strong>: 60000
            <br><strong>Unit</strong>: ms
            <br><strong>Assessment Window (minutes)</strong>: 10
        </td>
    </tr>
    <tr>
        <td>Can CF Login</td>
        <td>
            <strong>Name</strong>: health.check.<br/>cliCommand.login
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: CLI
        </td>
        <td>
            <strong>Threshold Type</strong>: INEQUALITY
            <br><strong>Critical</strong>: 0
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 10
        </td>
    </tr>
    <tr>
        <td>Can CF Push</td>
        <td>
            <strong>Name</strong>: health.check.<br/>cliCommand.push
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: CLI
        </td>
        <td>
            <strong>Threshold Type</strong>: INEQUALITY
            <br><strong>Critical</strong>: 0
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 10
        </td>
    </tr>
    <tr>
        <td>Can CF Start</td>
        <td>
            <strong>Name</strong>: health.check.<br/>cliCommand.start
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: CLI
        </td>
        <td>
            <strong>Threshold Type</strong>: INEQUALITY
            <br><strong>Critical</strong>: 0
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 10
        </td>
    </tr>
    <tr>
        <td>Can CF Stop</td>
        <td>
            <strong>Name</strong>: health.check.<br/>cliCommand.stop
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: CLI
        </td>
        <td>
            <strong>Threshold Type</strong>: INEQUALITY
            <br><strong>Critical</strong>: 0
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 10
        </td>
    </tr>
    <tr>
        <td>Can CF Delete</td>
        <td>
            <strong>Name</strong>: health.check.<br/>cliCommand.delete
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: CLI
        </td>
        <td>
            <strong>Threshold Type</strong>: INEQUALITY
            <br><strong>Critical</strong>: 0
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 10
        </td>
    </tr>
    <tr>
        <td>Can Receive Logs</td>
        <td>
            <strong>Name</strong>: health.check.<br/>cliCommand.logs
            <br><strong>Origin</strong>: healthwatch
            <br><strong>Category</strong>: CLI
        </td>
        <td>
            <strong>Threshold Type</strong>: INEQUALITY
            <br><strong>Critical</strong>: 0
            <br><strong>Unit</strong>: Number
            <br><strong>Assessment Window (minutes)</strong>: 10
        </td>
    </tr>
</table>

##<a id='errors'></a>Errors

This section lists common error messages and their causes.

---
**Error Message**: "Unsupported condition in query expression"

**Possible Cause**: Key in query string is something other than `name`, `origin`, `job`, or `deployment`

---
**Error Message**: "Unsupported query expression"

**Possible Causes**:

- Query string does not include AT LEAST `name` and `origin`
- Found operator other than `and` or `==`
- Expression in query string not in format of `property == 'value' and ...`

---
**Error Message**: "Invalid query expression"

**Possible Cause**: Invalid query string format

---
**Error Message**: "Invalid threshold type for metric 'some_origin.some_name'")

**Possible Cause**: Given threshold type does not match expected (see table above)

---
**Error Message**: "Must provide a warning threshold for an Upper/Lower Threshold"

**Possible Cause**: Threshold missing required values for type

---
**Error Message**: "name = 'some_name' and origin = 'some_origin' is not a supported alert configuration"
**Error Message**: "name = 'some_name', origin = 'some_origin', and job = 'some_job' is not a supported alert configuration"

**Possible Cause**: An alert configuration does not exist for the targeted metric

##<a id='Example'></a>Walkthrough Example

A best practice deployment of Cloud Foundry includes at least three availability zones (AZs). For these types of deployments, Pivotal recommends that you have enough capacity to suffer failure of an entire AZ.

By default, Healthwatch sends an alert if the `Diego.TotalPercentageAvailableMemoryCapacity.5M` metric falls below 35%, or one in three.

However, if your environment has been scaled up to five AZs you may wish to adjust the alert configuration accordingly to 20%, or more in five.

```
uaac token client get <my_healthwatch_admin_client> -s <my_healthwatch_admin_secret>
export token=$(uaac context | grep access_token | awk '{print $2}')

uaac curl -X POST "https://healthwatch-api.SYSTEM-DOMAIN/v1/alert-configurations"  \
      -H "Content-Type: application/json" \
      --data "{\"query\":\"origin == 'healthwatch' and name == 'Diego.TotalPercentageAvailableMemoryCapacity.5M'\",\"threshold\":{\"critical\":0.2,\"warning\":0.3,\"type\":\"LOWER\"}}"
```

The response body contains the updated alert configuration. You can then confirm the change:

```
uaac curl "https://healthwatch-api.SYSTEM-DOMAIN/v1/alert-configurations?q=origin == 'healthwatch' and name == 'Diego.TotalPercentageAvailableMemoryCapacity.5M'"
```
##<a id='event-alerts'></a>Configure PCF Healthwatch Alert Notifications

You can configure PCF Event Alerts to receive push notifications when a PCF Healthwatch alert occurs. For example, if you configured a PCF Healthwatch alert for memory on a VM, you can use PCF Event Alerts to receive a message on Slack if memory on the VM exceeds the threshold defined in the PCF Healthwatch alert.

For more information about configuring PCF Event Alerts for PCF Healthwatch, see [PCF Event Alerts](https://docs.pivotal.io/event-alerts/index.html).
