---
title: Configuring PCF Healthwatch Alerts
owner: PCF Healthwatch
---

This topic describes how to use the Pivotal Cloud Foundry (PCF) Healthwatch API to retrieve and configure alert configurations.

Currently, two main types of alert configurations are supported: Out-of-the-Box and Deployment-specific. Through this API, consumers can do the following:

- View current alert configurations
- Update Out-of-the-Box threshold values
- Create deployment-specific configurations based on existing Out-of-the-Box configurations

##<a id='prerequisites'></a>Prerequisites/Assumptions

The steps in this document assume that you can [generate bearer tokens for a UAA client](https://docs.cloudfoundry.org/uaa/uaa-user-management.html) with the `healthwatch.read` (`GET` only) and `healthwatch.admin` (both `GET` and `POST`) scopes.

After creating a user that has `healthwatch.read` or `healthwatch.admin` scopes, follow these steps to authenticate against UAA:

```
uaac token client get <my_healthwatch_admin_client> -s <my_healthwatch_admin_secret>
```

At this point you are properly authenticated and ready to start using the Healthwatch Alerts API.

##<a id='info'></a>Healthwatch API Status

Test the availability of the Healthwatch API by hitting the `/info` endpoint with a `GET` request:

```
curl -G healthwatch-api.SYSTEM-DOMAIN/info
```

The expected response is a `200`/`OK` with the message `"HAPI is happy"`.

##<a id='get'></a>View all alert configurations
### `GET /alert-configurations`

To view a list of alert configurations, send a `GET` request to the `/alert-configurations` endpoint:

```
uaac curl -G healthwatch-api.SYSTEM-DOMAIN/v1/alert-configurations
```

This returns a JSON array of alert configurations:

```
[
    {
        "query": "origin == 'some_origin' and name == 'Some.Metric.Name'",
        "threshold": {
            "critical": 95,
            "warning": 85,
            "type": "UPPER"
        }
    },
    {
        "query": "origin == 'some_origin' and name == 'Another.Metric.Name'",
        "threshold": {
            "critical": 9,
            "warning": 28,
            "type": "LOWER"
        }
    },
    {
        "query": "origin == 'another_origin' and name == 'Some.Metric.Name'",
        "threshold": {
            "critical": 1,
            "type": "EQUALITY"
        }
    }
]
```

The `query` and `threshold` properties are covered in detail below.

##<a id='get_with_query'></a>View specific alert configurations
### `GET /alert-configurations?q=...`

To narrow the results of a `GET` request, add a `query` to the URL in a parameter named `q`:

```
uaac curl -G "healthwatch-api.SYSTEM-DOMAIN/v1/alert-configurations"  \
    --data-urlencode "q=origin == 'some_origin' and name == 'Some.Metric.Name'" 
```

This returns a JSON array of alert configurations, filtered against the provideded `query`:

```
[
    {
        "query": "origin == 'some_origin' and name == 'Some.Metric.Name'",
        "threshold": {
            "critical": 95,
            "warning": 85,
            "type": "UPPER"
        }
    }
]
```

##<a id='post'></a>Updating alert configurations

### `POST /alert-configurations`

To update an existing alert configuration, make a `POST` request to the `alert_configurations` endpoint with the updated data:

```
uaac curl "healthwatch-api.SYSTEM-DOMAIN/v1/alert-configurations"  \
      --data "{\"query\":\"origin == 'some_origin' and name == 'Some.Metric.Name'\",\"threshold\":{\"critical\":90,\"warning\":80,\"type\":\"UPPER\"}}" \
      -H "Content-Type: application/json"
```

The updated alert configuration is echoed back in the response:

```
{
    "query": "origin == 'some_origin' and name == 'Some.Metric.Name'",
    "threshold": {
        "critical": 95,
        "warning": 85,
        "type": "UPPER"
    }
}
```

##<a id='queries'></a>Queries

The `query` field is used in two ways:

* `GET` requests: The `query` filters the alert configurations being queried.
* `POST` requests: The `query` specifies the alert configuration being updated.

In both cases, the `query` associated with an alert configuration denotes the trigger conditions for the alert.

A well-formed `query` is a valid [Spring Expression Language (SpEL)](https://docs.spring.io/spring/docs/4.3.14.RELEASE/spring-framework-reference/html/expressions.html) expression that uses only the equality, `"=="`, and conjunction, `"and"`, operators. For example:

```
"origin == 'some_origin' and name == 'Some.Metric.Name'"  # valid
"origin  > 'some_origin' and name == 'Some.Metric.Name'"  # invalid (uses '>')
"origin == 'some_origin'  or name == 'Some.Metric.Name'"  # invalid (uses 'or')
```

The following fields can be queried:

- `origin`&nbsp;&nbsp;&nbsp;*(required)*
- `name`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*(required)*
- `job`
- `deployment`

##<a id='thresholds'></a>Thresholds

The `threshold` field contains a threshold `type`, as well as `critical` and `warning` threshold values. The `type` can be `"UPPER"`, `"LOWER"`, `"EQUALITY"`, or `"INEQUALITY"`.

Alert configurations whose thresholds are of the `UPPER` type trigger their alerts when the actual metric value is *above* the `warning` value, and again when above the `critical` value.

Thresholds with the `LOWER` type work the same way, except the alerts trigger when the metric falls *below* the thresholds.

The `EQUALITY` alerts trigger when the metric value is **not** exactly equal to the `critical` threshold. These alerts do not have `warning` thresholds.

The `INEQUALITY` alerts trigger when the metric value **is** exactly equal to the `critical` threshold. These alerts do not have `warning` thresholds.

##<a id='defaults'></a>Supported Alerts

Healthwatch ships with the following configurable alerts:

| Description                                                                | Metric Name                                        | Metric Origin                 | Job                     | Category            | Threshold Type | Critical     | Warning    | Unit    | Assessment Window (minutes) |
|----------------------------------------------------------------------------|----------------------------------------------------|-------------------------------|-------------------------|---------------------|----------------|--------------|------------|---------|-----------------------------|
| Performance Alert: Active Locks Held                                       | ActiveLocks	                                      | locket	                      |                         | Compute Performance | EQUALITY       | 4            |            | Number  | 5                           |
| Performance Alert: Active Presences Held<sup>1</sup>                       | ActivePresences	                                  | locket	                      |                         | Compute Performance | UPPER          | 200          | 150        | Number  | 15                          |
| Performance Alert: Auctioneer Time to Fetch Cell State                     | AuctioneerFetchStatesDuration                      | auctioneer                    |                         | Compute Performance | UPPER          | 5000000000   | 2000000000 | ns      | 5                           |
| Performance Alert: App Instances Placement Failures Rate                   | AuctioneerLRPAuctionsFailed                        | auctioneer                    |                         | App Instances       | UPPER          | 1            | .5         | Number  | 5                           |
| Performance Alert: App Instance Starts Rate<sup>1</sup>                    | AuctioneerLRPAuctionsStarted                       | auctioneer                    |                         | App Instances       | UPPER          | 100          | 50         | Number  | 5                           |
| Performance Alert: Router Exhausted Connections<sup>1</sup>                | backend\_exhausted\_conns                          | gorouter                      |                         | Routing             | UPPER          | 10           | 5          | Number  | 5                           |
| Performance Alert: Number of Router 502 Bad Gateways<sup>1</sup>           | bad_gateways                                       | gorouter                      |                         | Routing             | UPPER          | 40           | 30         | Number  | 5                           |
| Performance Alert: Task Placement Failures Rate                            | AuctioneerTaskAuctionsFailed                       | auctioneer                    |                         | App Instances       | UPPER          | 1            | .5         | Number  | 5                           |
| Performance Alert: BBS Time to Run LRP Convergence                         | ConvergenceLRPDuration                             | bbs                           |                         | Compute Performance | UPPER          | 20000000000  | 10000000000| ns      | 15                          |
| Performance Alert: Number of Crashed App Instances<sup>1</sup>             | CrashedActualLRPs                                  | bbs                           |                         | App Instances       | UPPER          | 20           | 10         | Number  | 5                           |
| Performance Alert: Cloud Controller and Diego in Sync                      | Diego.AppsDomainSynced                             | bbs                           |                         | Compute Performance | EQUALITY       | 1            |            | Number  | 5                           |
| Scaling Alert: Number of Available Free Chunks of Cell Memory              | Diego.AvailableFreeChunks                          | healthwatch                   |                         | Capacity            | LOWER          | 1            | 2          | Number  | 5                           |
| Scaling Alert: Number of Available Free Chunks of Cell Disk                | Diego.AvailableFreeChunksDisk                      | healthwatch                   |                         | Capacity            | LOWER          | 50           | 100        | Number  | 5                           |
| Performance Alert: Rate of Change in Running App Instances<sup>1</sup>     | Diego.LRPsAdded.1H                                 | healthwatch                   |                         | App Instances       | UPPER          | 100          | 50         | Number  | 5                           |
| Scaling Alert: Remaining Cell Disk Available                               | Diego.TotalAvailableDiskCapacity.5M                | healthwatch                   |                         | Capacity            | LOWER          | 6144         | 12288      | MBs     | 5                           |
| Scaling Diego: Remaining Cell Memory Available<sup>1</sup>                 | Diego.TotalAvailableMemoryCapacity.5M              | healthwatch                   |                         | Capacity            | LOWER          | 32768        | 65536      | MBs     | 5                           |
| Scaling Alert: Cell Container Capacity Available                           | Diego.TotalPercentageAvailableContainerCapacity.5M | healthwatch                   |                         | Capacity            | LOWER          | 0.35         | 0.4        | Percent | 30                          |
| Scaling Alert: Cell Disk Available                                         | Diego.TotalPercentageAvailableDiskCapacity.5M      | healthwatch                   |                         | Capacity            | LOWER          | 0.35         | 0.4        | Percent | 30                          |
| Scaling Alert: Cell Memory Available<sup>1</sup>                           | Diego.TotalPercentageAvailableMemoryCapacity.5M    | healthwatch                   |                         | Capacity            | LOWER          | 0.35         | 0.4        | Percent | 30                          |
| Scaling Alert: Doppler Message Rate Capacity                               | Doppler.MessagesAverage.1M                         | healthwatch                   |                         | Logging             | UPPER          | 1000000      | 800000     | Number  | 60                          |
| Performance Alert: Router File Descriptors                                 | file_descriptors                                   | gorouter                      |                         | Routing             | UPPER          | 60000        | 50000      | Number  | 5                           |
| Scaling Alert: Log Transport Loss Rate                                     | Firehose.LossRate.1M                               | healthwatch                   |                         | Logging             | UPPER          | 0.01         | 0.005      | Percent | 5                           |
| Performance Alert: PAS MySQL Galera Cluster Status                         | Galera.ClusterStatusSum                            | healthwatch                   |                         | MySQL               | LOWER          | 0.9999       | 2.9999     | Number  | 5                           |
| Performance Alert: PAS MySQL Galera Cluster Size                           | Galera.TotalPercentageHealthyNodes                 | healthwatch                   |                         | MySQL               | LOWER          | 0.3332       | 0.9999     | Percent | 5                           |
| Performance Alert: Healthwatch BOSH Director Test Availability             | health.check.bosh.director.probe.available         | healthwatch                   |                         | BOSH Director       | LOWER          | 0.4          | 0.6        | Number  | 10                          |
| Service Level Indicator Alert: BOSH Director Health                        | health.check.bosh.director.success                 | healthwatch                   |                         | BOSH Director       | EQUALITY       | 1            |            | Number  | 10                          |
| Service Level Indicator Alert: Ops Manager Availability                    | health.check.OpsMan.available                      | healthwatch                   |                         | Ops Manager         | LOWER          | 0.5          |            | Number  | 5                           |
| Performance Alert: Ops Manager Test Availability                           | health.check.OpsMan.probe.available                | healthwatch                   |                         | Ops Manager         | LOWER          | 0.4          | 0.6        | Number  | 5                           |
| Service Level Indicator Alert: Canary App Availability                     | health.check.CanaryApp.available                   | healthwatch                   |                         | Canary App          | LOWER          | 0.5          |            | Number  | 5                           |
| Performance Alert: Canary App Health Test Availability                     | health.check.CanaryApp.probe.available             | healthwatch                   |                         | Canary App          | LOWER          | 0.4          | 0.6        | Number  | 5                           |
| Service Level Indicator Alert: Canary App Response Time                    | health.check.CanaryApp.responseTime                | healthwatch                   |                         | Canary App          | UPPER          | 30000        | 15000      | ms      | 5                           |
| Service Level Indicator Alert: CF Push Time                                | health.check.cliCommand.pushTime                   | healthwatch                   |                         | CLI                 | UPPER          | 120000       | 60000      | ms      | 10                          |
| Service Level Indicator Alert: Can CF Login                                | health.check.cliCommand.login                      | healthwatch                   |                         | CLI                 | INEQUALITY     | 0            |            | Number  | 10                          |
| Service Level Indicator Alert: Can CF Push                                 | health.check.cliCommand.push                       | healthwatch                   |                         | CLI                 | INEQUALITY     | 0            |            | Number  | 10                          |
| Service Level Indicator Alert: Can CF Start                                | health.check.cliCommand.start                      | healthwatch                   |                         | CLI                 | INEQUALITY     | 0            |            | Number  | 10                          |
| Service Level Indicator Alert: Can CF Stop                                 | health.check.cliCommand.stop                       | healthwatch                   |                         | CLI                 | INEQUALITY     | 0            |            | Number  | 10                          |
| Service Level Indicator Alert: Can CF Delete                               | health.check.cliCommand.delete                     | healthwatch                   |                         | CLI                 | INEQUALITY     | 0            |            | Number  | 10                          |
| Service Level Indicator Alert: Can Receive Logs                            | health.check.cliCommand.logs                       | healthwatch                   |                         | CLI                 | INEQUALITY     | 0            |            | Number  | 10                          |
| Performance Alert: CLI Health Test Availability                            | health.check.cliCommand.probe.available            | healthwatch                   |                         | CLI                 | LOWER          | 0.4          | 0.6        | Number  | 5                           |
| Performance Alert: Healthwatch UI Availability                             | health.check.ui.available                          | healthwatch                   |                         | Healthwatch         | LOWER          | 0.4          | 0.6        | Number  | 5                           |
| Performance Alert: Healthwatch Nozzle Disconnects                          | ingestor.disconnects                               | healthwatch                   |                         | Healthwatch         | UPPER          | 10           | 5          | Number  | 5                           |
| Performance Alert: Healthwatch Ingestor Data Drops                         | ingestor.dropped                                   | healthwatch                   |                         | Healthwatch         | UPPER          | 20           | 10         | Number  | 5                           |
| Performance Alert: Healthwatch Ingestor Metrics Ingested                   | ingestor.ingested                                  | healthwatch                   |                         | Healthwatch         | LOWER          | 0.01         | 0.01       | Number  | 30                          |
| Performance Alert: Healthwatch Ingestor BOSH System Metrics Ingested       | ingestor.ingested.boshSystemMetrics                | healthwatch                   |                         | Healthwatch         | LOWER          | 0.01         | 0.01       | Number  | 30                          |
| Performance Alert: Router Handling Latency<sup>1</sup>                     | latency                                            | gorouter                      |                         | Routing             | UPPER          | 150          | 100        | ms      | 30                          |
| Performance Alert: UAA Request Latency                                     | latency.uaa                                        | gorouter                      |                         | Routing             | UPPER          | 150          | 100        | ms      | 5                           |
| Performance Alert: Locks Held by BBS                                       | LockHeld                                           | bbs                           |                         | Healthwatch         | EQUALITY       | 1            |            | Number  | 5                           |
| Performance Alert: Locks Held by Auctioneer                                | LockHeld                                           | auctioneer                    |                         | Compute Performance | EQUALITY       | 1            |            | Number  | 5                           |
| Performance Alert: More App Instances Than Expected                        | LRPsExtra                                          | bbs                           |                         | App Instances       | UPPER          | 10           | 5          | Number  | 5                           |
| Performance Alert: Fewer App Instances Than Expected                       | LRPsMissing                                        | bbs                           |                         | App Instances       | UPPER          | 10           | 5          | Number  | 5                           |
| Performance Alert: Healthwatch Super Metrics Published                     | metrics.published                                  | healthwatch                   |                         | Healthwatch         | LOWER          | 0            | 20         | Number  | 5                           |
| Performance Alert: Time Since Last Route Register Received                 | ms\_since\_last\_registry\_update                  | gorouter                      |                         | Routing             | UPPER          | 30000        | 30000      | ms      | 5                           |
| Performance Alert: PAS MySQL Server Availability                           | /mysql/available                                   | mysql                         | mysql,database          | MySQL               | EQUALITY       | 1            |            | Number  | 5                           |
| Performance Alert: PAS MySQL Galera Cluster Node Readiness                 | /mysql/galera/wsrep_ready	                      | mysql	                      | mysql,database          | MySQL               | LOWER          | 1            | 0.9999     | Number  | 5                           |
| Scaling Alert: Redis Counter Event Queue Size                              | redis.counterEventQueue.size                       | healthwatch                   |                         | Healthwatch         | UPPER          | 10000        |            | Number  | 5                           |
| Scaling Alert: Redis Value Metric Queue Size                               | redis.valueMetricQueue.size                        | healthwatch                   |                         | Healthwatch         | UPPER          | 10000        |            | Number  | 5                           |
| Performance Alert: Cell Rep Time to Sync                                   | RepBulkSyncDuration                                | rep                           |                         | Compute Performance | UPPER          | 10000000000  | 5000000000 | ns      | 15                          |
| Performance Alert: Number of Router 5XX Server Errors<sup>1</sup>          | responses.5xx                                      | gorouter                      |                         | Routing             | UPPER          | 40           | 30         | Number  | 5                           |
| Performance Alert: Route Emitter Time to Sync<sup>1</sup>                  | RouteEmitterSyncDuration                           | route_emitter                 |                         | Compute Performance | UPPER          | 10000000000  | 5000000000 | ns      | 15                          |
| Performance Alert: Number of Route Registration Messages Sent and Received | RouteRegistration.MessagesDelta                    | healthwatch                   |                         | Routing             | UPPER          | 50           | 30         | Number  | 5                           |
| Performance Alert: BBS Time to Handle Requests                             | RequestLatency                                     | bbs                           |                         | Compute Performance | UPPER          | 10000000000  | 5000000000 | ns      | 15                          |
| Performance Alert: UAA Requests In Flight                                  | server.inflight.count                              | uaa                           |                         | UAA                 | UPPER          | 200          | 150        | Number  | 5                           |
| Scaling Alert: Syslog Adapter Capacity                                     | SyslogDrain.Adapter.BindingsAverage.5M             | healthwatch                   |                         | Logging             | UPPER          | 250          | 200        | Number  | 60                          |
| Scaling Alert: Syslog Adapter Loss Rate                                    | SyslogDrain.Adapter.LossRate.1M                    | healthwatch                   |                         | Logging             | UPPER          | 0.1          | 0.01       | Percent | 5                           |
| Scaling Alert: Reverse Log Proxy Loss Rate                                 | SyslogDrain.RLP.LossRate.1M                        | healthwatch                   |                         | Logging             | UPPER          | 0.1          | 0.01       | Percent | 5                           |
| Scaling Alert: Router Instance CPU                                         | system.cpu.user                                    | bosh-system-metrics-forwarder | router                  | Routing             | UPPER          | 70           | 60         | Percent | 5                           |
| Scaling Alert: UAA Instance CPU                                            | system.cpu.user                                    | bosh-system-metrics-forwarder | uaa,control<sup>3</sup> | UAA                 | UPPER          | 90           | 80         | Percent | 5                           |
| Performance Alert: VM CPU                                                  | system.cpu.user                                    | bosh-system-metrics-forwarder |                         | All Jobs            | UPPER          | 95           | 85         | Percent | 5                           |
| Performance Alert: VM Ephemeral Disk Used                                  | system.disk.ephemeral.percent                      | bosh-system-metrics-forwarder |                         | All Jobs            | UPPER          | 90           | 80         | Percent | 5                           |
| Performance Alert: VM Persistent Disk Used                                 | system.disk.persistent.percent                     | bosh-system-metrics-forwarder |                         | All Jobs            | UPPER          | 90           | 80         | Percent | 5                           |
| Performance Alert: VM Disk Used                                            | system.disk.system.percent                         | bosh-system-metrics-forwarder |                         | All Jobs            | UPPER          | 90           | 80         | Percent | 5                           |
| Performance Alert: VM Health Check Recovery                                | system.healthy                                     | bosh-system-metrics-forwarder |                         | All Jobs            | LOWER          | 0.4          | 0.6        | Number  | 5                           |
| Performance Alert: Router Throughput<sup>1</sup>                           | total_requests                                     | gorouter                      |                         | Routing             | UPPER          | 125000       | 100000     | Number  | 5                           |
| Performance Alert: Number of Router Routes Registered<sup>1</sup>          | total_routes                                       | gorouter                      |                         | Routing             | UPPER          | 200          | 100        | Number  | 5                           |
| Performance Alert: VM Memory Used                                          | system.mem.percent                                 | bosh-system-metrics-forwarder |                         | All Jobs            | UPPER          | 95           | 85         | Percent | 5                           |
| Performance Alert: UAA Throughput Rate                                     | uaa.throughput.rate                                | healthwatch                   |                         | Healthwatch         | UPPER          | 15000        | 12000      | Number  | 5                           |
| Performance Alert: Unhealthy Cells<sup>2</sup>                             | UnhealthyCell                                      | rep                           |                         | Compute Performance | EQUALITY       | 0            |            | Number  | 5                           |

You can learn more about the metrics PCF Healthwatch emits here: [PCF Healthwatch Metrics](../metrics.html).

<sup>1</sup> While these metrics are highly important to watch, the relative numbers to set threshold warnings at are specific to a given PCF environment and its use cases. These dynamic thresholds should be occasionally revisited because the PCF foundation and its usage continue to evolve. See [Determine Warning and Critical Thresholds](https://docs.pivotal.io/pivotalcf/2-1/monitoring/metrics.html#thresholds) for more information.<br/>
<sup>2</sup> We are alerting by cell for this metric. We will notify at a critical level when any Diego Cell has been unhealthy for 5 minutes.<br/>
<sup>3</sup> This handles two jobs to accommodate different job names between PAS and SRT*

##<a id='errors'></a>Errors

This section lists common error messages and their causes.

---
**Error Message**: "Unsupported condition in query expression"

**Possible Cause**: Key in query string is something other than `name`, `origin`, `job`, or `deployment`

---
**Error Message**: "Unsupported query expression"

**Possible Causes**:

- Query string does not include AT LEAST `name` and `origin`
- Found operator other than `and` or `==`
- Expression in query string not in format of `property == 'value' and ...`

---
**Error Message**: "Invalid query expression"

**Possible Cause**: Invalid query string format

---
**Error Message**: "Invalid threshold type for metric 'some_origin.some_name'")

**Possible Cause**: Given threshold type does not match expected (see table above)

---
**Error Message**: "Must provide a warning threshold for an Upper/Lower Threshold"

**Possible Cause**: Threshold missing required values for type

---
**Error Message**: "name = '${alertConfiguration.name}' and origin = '${alertConfiguration.origin}' is not a supported alert configuration"

**Possible Cause**: Alert configuration does not exist for the targeted metric

##<a id='Example'></a>Walkthrough Example

A best practice deployment of Cloud Foundry includes at least three availability zones (AZs). For these types of deployments, Pivotal recommends that you have enough capacity to suffer failure of an entire AZ.

By default, Healthwatch sends an alert if the `Diego.TotalPercentageAvailableMemoryCapacity.5M` metric falls below 35%, or one in three.

However, if your environment has been scaled up to five AZs you may wish to adjust the alert configuration accordingly to 20%, or more in five.

```
uaac token client get <my_healthwatch_admin_client> -s <my_healthwatch_admin_secret>
export token=$(uaac context | grep access_token | awk '{print $2}')

uaac curl "healthwatch-api.SYSTEM-DOMAIN/v1/alert-configurations"  \
      --data "{\"query\":\"origin == 'healthwatch' and name == 'Diego.TotalPercentageAvailableMemoryCapacity.5M'\",\"threshold\":{\"critical\":0.2,\"warning\":0.3,\"type\":\"LOWER\"}}" \
      -H "Content-Type: application/json"
```

The response body contains the updated alert configuration. You can confirm the change with a `GET` request:

```
uaac curl -G "healthwatch-api.SYSTEM-DOMAIN/v1/alert-configurations"  \
    --data-urlencode "q=origin == 'healthwatch' and name == 'Diego.TotalPercentageAvailableMemoryCapacity.5M'" 
```
